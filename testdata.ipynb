{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_dataset\n",
    "from model import ClimatePINN\n",
    "from train import plot_comparison\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import xarray as xr\n",
    "from visualisation import visualize_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading model with configuration: hidden_dim=64, initial_re=100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enzolouv/Documents/ENS PS 2024-2025/cours/projet_IA/PINN_Climate/visualisation.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for 72 frames...\n",
      "Processing frame 1/72\n",
      "Processing frame 2/72\n",
      "Processing frame 3/72\n",
      "Processing frame 4/72\n",
      "Processing frame 5/72\n",
      "Processing frame 6/72\n",
      "Processing frame 7/72\n",
      "Processing frame 8/72\n",
      "Processing frame 9/72\n",
      "Processing frame 10/72\n",
      "Processing frame 11/72\n",
      "Processing frame 12/72\n",
      "Processing frame 13/72\n",
      "Processing frame 14/72\n",
      "Processing frame 15/72\n",
      "Processing frame 16/72\n",
      "Processing frame 17/72\n",
      "Processing frame 18/72\n",
      "Processing frame 19/72\n",
      "Processing frame 20/72\n",
      "Processing frame 21/72\n",
      "Processing frame 22/72\n",
      "Processing frame 23/72\n",
      "Processing frame 24/72\n",
      "Processing frame 25/72\n",
      "Processing frame 26/72\n",
      "Processing frame 27/72\n",
      "Processing frame 28/72\n",
      "Processing frame 29/72\n",
      "Processing frame 30/72\n",
      "Processing frame 31/72\n",
      "Processing frame 32/72\n",
      "Processing frame 33/72\n",
      "Processing frame 34/72\n",
      "Processing frame 35/72\n",
      "Processing frame 36/72\n",
      "Processing frame 37/72\n",
      "Processing frame 38/72\n",
      "Processing frame 39/72\n",
      "Processing frame 40/72\n",
      "Processing frame 41/72\n",
      "Processing frame 42/72\n",
      "Processing frame 43/72\n",
      "Processing frame 44/72\n",
      "Processing frame 45/72\n",
      "Processing frame 46/72\n",
      "Processing frame 47/72\n",
      "Processing frame 48/72\n",
      "Processing frame 49/72\n",
      "Processing frame 50/72\n",
      "Processing frame 51/72\n",
      "Processing frame 52/72\n",
      "Processing frame 53/72\n",
      "Processing frame 54/72\n",
      "Processing frame 55/72\n",
      "Processing frame 56/72\n",
      "Processing frame 57/72\n",
      "Processing frame 58/72\n",
      "Processing frame 59/72\n",
      "Processing frame 60/72\n",
      "Processing frame 61/72\n",
      "Processing frame 62/72\n",
      "Processing frame 63/72\n",
      "Processing frame 64/72\n",
      "Processing frame 65/72\n",
      "Processing frame 66/72\n",
      "Processing frame 67/72\n",
      "Processing frame 68/72\n",
      "Processing frame 69/72\n",
      "Processing frame 70/72\n",
      "Processing frame 71/72\n",
      "Processing frame 72/72\n",
      "Saving animation to visualizations/temperature_prediction_epoch_67.mp4\n",
      "Saving animation to visualizations/temperature_true_epoch_67.mp4\n",
      "Saving animation to visualizations/wind_prediction_epoch_67.mp4\n",
      "Saving animation to visualizations/wind_true_epoch_67.mp4\n",
      "Saved animations in visualizations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "checkpoint_path = \"checkpoints/run_1.pt\"  # Update with your checkpoint path\n",
    "data_dir = \"./data/era_5_data\"  # Update with your data directory\n",
    "visualize_predictions(checkpoint_path, data_dir,72)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
