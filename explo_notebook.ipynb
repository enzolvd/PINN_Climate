{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **0.Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_dataset\n",
    "# from models.model_2_dropout_imp import ClimatePINN\n",
    "from train import plot_comparison\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import xarray as xr\n",
    "from video_gen import load_checkpoint\n",
    "import json\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1.Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    1, \n",
    "    train_val_split = None, \n",
    "    year0=2000, \n",
    "    root_dir=\"./data/era_5_data\",\n",
    "    normalize=True)\n",
    "\n",
    "idx = [0,1,2]\n",
    "inputs, targets = dataset['train'][:]['input'], dataset['train'][:]['target']\n",
    "geo500 , t850 = inputs[:,0,...], inputs[:,1,...]\n",
    "t2m, u, v = targets[:,0,...], targets[:,1,...], targets[:,2,...]\n",
    "inputs = (geo500 , t850)\n",
    "targets = (t2m, u, v)\n",
    "lon, lat= dataset['train'][0]['coords'][0], dataset['train'][0]['coords'][1]\n",
    "dataloader = DataLoader(dataset['train'], batch_size=1, shuffle=False)\n",
    "batch = next(iter(dataloader))\n",
    "inputs = batch['input']\n",
    "targets = batch['target']\n",
    "masks = batch['masks']\n",
    "coords = [coord for coord in batch['coords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = (geo500 , t850, t2m, u, v)\n",
    "\n",
    "corr_matrix = np.zeros((5,5))\n",
    "vars_name = ['input:geo500', 'input:t850', 'target:t2m', 'target:u', 'target:v']\n",
    "corr_matrix = np.zeros((5, 5, 32, 64))\n",
    "import matplotlib.colors as mcolors\n",
    "norm = mcolors.Normalize(vmin=-1, vmax=1)\n",
    "for x, var_x in tqdm(enumerate(vars)):\n",
    "    for y, var_y in enumerate(vars):\n",
    "        corr = pearsonr(var_x, var_y)[0]\n",
    "        corr_matrix[x,y] = corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the arrays\n",
    "vars = (geo500.flatten(), t850.flatten(), t2m.flatten(), u.flatten(), v.flatten())\n",
    "vars_name = ['geo500', 't850', 't2m', 'u', 'v']\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = np.zeros((5, 5))\n",
    "for x, var_x in tqdm(enumerate(vars)):\n",
    "    for y, var_y in enumerate(vars):\n",
    "        corr = pearsonr(var_x, var_y)[0]\n",
    "        corr_matrix[x, y] = corr\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot the correlation matrix\n",
    "im = ax.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "\n",
    "# Add color bar\n",
    "cbar = fig.colorbar(im, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Correlation Coefficient')\n",
    "\n",
    "# Add labels to the matrix\n",
    "ax.set_xticks(np.arange(len(vars_name)))\n",
    "ax.set_yticks(np.arange(len(vars_name)))\n",
    "ax.set_xticklabels(vars_name)\n",
    "ax.set_yticklabels(vars_name)\n",
    "\n",
    "# Rotate the tick labels for better readability\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Add separators\n",
    "ax.axvline(x=1.5, color='black', linewidth=2)\n",
    "ax.axhline(y=1.5, color='black', linewidth=2)\n",
    "\n",
    "# Annotate the cells with the correlation coefficients\n",
    "for i in range(len(vars_name)):\n",
    "    for j in range(len(vars_name)):\n",
    "        text = ax.text(j, i, f\"{corr_matrix[i, j]:.2f}\",\n",
    "                       ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "# Add title\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\n",
    "    10, \n",
    "    train_val_split = 0.8,\n",
    "    root_dir=\"./data/era_5_data\",\n",
    "    year0=1979,\n",
    "    normalize=True)\n",
    "\n",
    "train_dataset, val_dataset = dataset['train'], dataset['val']\n",
    "test_dataset = load_dataset(\n",
    "    1,\n",
    "    train_val_split = None,\n",
    "    year0=2000,\n",
    "    root_dir=\"./data/era_5_data\",\n",
    "    normalize=True)['train']\n",
    "bs = 16 \n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to collect results\n",
    "results_data = []\n",
    "\n",
    "# Define a dictionary of loaders to loop over\n",
    "loaders = {\"train\": train_loader, \"val\": val_loader,\"test\": test_loader} # \n",
    "runs = ['run_1', 'run_3', 'run_4', 'run_8', 'run_9']\n",
    "\n",
    "for run in tqdm(runs, leave=False, desc=\"Processing runs\"):\n",
    "    model, epoch, config, device, model_name = load_checkpoint(run, device, checkpoints='./checkpoints', verbose=False)\n",
    "    \n",
    "    for ds_name, loader in tqdm(loaders.items(), leave=False, desc=f\"Datasets for {model_name}\"):\n",
    "        model.eval()\n",
    "        mse_loss = 0.0\n",
    "        phy_loss = 0.0\n",
    "        count = 0\n",
    "        \n",
    "        for batch in tqdm(loader, leave=False, desc=f\"Batches in {ds_name}\"):\n",
    "            inp = batch['input'].to(device)\n",
    "            masks = batch['masks'].to(device)\n",
    "            coords = [coord.to(device) for coord in batch['coords']]\n",
    "            target = batch['target'].to(device)\n",
    "            \n",
    "            pred = model(inp, masks, coords)\n",
    "            loss = model.MSE(pred['output'], target)\n",
    "            mse_loss += loss.item()\n",
    "            phy_loss += sum(list(pred['physics_loss'].values())).item()\n",
    "            count += 1\n",
    "            \n",
    "            del inp, masks, coords, target, pred, loss\n",
    "            torch.cuda.empty_cache()\n",
    "                    \n",
    "        avg_mse_loss = mse_loss / count if count > 0 else float('nan')\n",
    "        avg_phy_loss = phy_loss / count if count > 0 else float('nan')\n",
    "        \n",
    "        # Append results to list\n",
    "        results_data.append({\n",
    "            'model_name': model_name,\n",
    "            'dataset': ds_name,\n",
    "            'mse': avg_mse_loss,\n",
    "            'physics_loss': avg_phy_loss,\n",
    "            'total_loss': avg_mse_loss + avg_phy_loss\n",
    "        })\n",
    "        \n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Create DataFrame from collected results after all processing is done\n",
    "results_df = pd.DataFrame(results_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('./outputs/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('./outputs/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the seaborn style \n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Option 1: Specify the number of colors needed\n",
    "palette = sns.color_palette(\"Set1\", n_colors=3)\n",
    "\n",
    "# Option 2: Or use a specific palette that's commonly used in pairplots\n",
    "# palette = sns.color_palette(\"deep\")\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "sns.barplot(x='model_name', y='mse', hue='dataset', data=results_df, ax=ax[0], palette=palette)\n",
    "ax[0].set_title(\"MSE Loss\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].set_yscale(\"log\")\n",
    "\n",
    "sns.barplot(x='model_name', y='physics_loss', hue='dataset', data=results_df, ax=ax[1], palette=palette)\n",
    "ax[1].set_title(\"Physics Loss\")\n",
    "ax[1].set_ylabel(\"Loss\")\n",
    "ax[1].set_yscale(\"log\")\n",
    "\n",
    "sns.barplot(x='model_name', y='total_loss', hue='dataset', data=results_df, ax=ax[2], palette=palette)\n",
    "ax[2].set_title(\"Total Loss\")\n",
    "ax[2].set_ylabel(\"Loss\")\n",
    "ax[2].set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./outputs/barplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming results_df already exists with columns 'model_name', 'dataset', 'mse', 'physics_loss', 'total_loss'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Replace underscores in model names for LaTeX display\n",
    "results_df['model_display'] = results_df['model_name'].apply(lambda x: x.replace('_', r'\\_'))\n",
    "\n",
    "# Find the best (minimum) values for each metric in each dataset\n",
    "best_values = {}\n",
    "for dataset in ['train', 'val', 'test']:\n",
    "    dataset_df = results_df[results_df['dataset'] == dataset]\n",
    "    for metric in ['mse', 'physics_loss', 'total_loss']:\n",
    "        best_values[(dataset, metric)] = dataset_df[metric].min()\n",
    "\n",
    "# Format values with scientific notation where appropriate\n",
    "def format_value(value, is_best=False):\n",
    "    if np.isnan(value):\n",
    "        return \"N/A\"\n",
    "    # Use scientific notation for very small values\n",
    "    elif abs(value) < 0.001 or abs(value) >= 10000:\n",
    "        formatted = f\"{value:.2e}\"\n",
    "    else:\n",
    "        formatted = f\"{value:.4f}\"\n",
    "    \n",
    "    # Add bold formatting for best values\n",
    "    if is_best:\n",
    "        return f\"\\\\textbf{{{formatted}}}\"\n",
    "    return formatted\n",
    "\n",
    "# Get unique model names (preserving order)\n",
    "unique_models = results_df[results_df['dataset'] == 'train']['model_name'].tolist()\n",
    "model_displays = results_df[results_df['dataset'] == 'train']['model_display'].tolist()\n",
    "\n",
    "# Create a reorganized table by metric type\n",
    "latex_table = r\"\"\"\\begin{table}[htbp]\n",
    "\\centering\n",
    "\\caption{Comparison of models across different metrics and datasets. Best values in each category are highlighted in bold.}\n",
    "\\label{tab:results}\n",
    "\\begin{tabular}{lcccc}\n",
    "\\toprule\n",
    "& \\multicolumn{4}{c}{MSE} \\\\\n",
    "\\cmidrule(lr){2-5}\n",
    "Model & Train & Val & Test & Average \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "# MSE section\n",
    "for i, model_name in enumerate(unique_models):\n",
    "    model_display = model_displays[i]\n",
    "    \n",
    "    mse_train = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'train')]['mse'].values[0]\n",
    "    mse_val = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'val')]['mse'].values[0]\n",
    "    mse_test = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'test')]['mse'].values[0]\n",
    "    mse_avg = (mse_train + mse_val + mse_test) / 3\n",
    "    \n",
    "    is_best_mse_train = abs(mse_train - best_values[('train', 'mse')]) < 1e-10\n",
    "    is_best_mse_val = abs(mse_val - best_values[('val', 'mse')]) < 1e-10\n",
    "    is_best_mse_test = abs(mse_test - best_values[('test', 'mse')]) < 1e-10\n",
    "    \n",
    "    latex_table += f\"{model_display} & {format_value(mse_train, is_best_mse_train)} & {format_value(mse_val, is_best_mse_val)} & {format_value(mse_test, is_best_mse_test)} & {format_value(mse_avg)} \\\\\\\\\\n\"\n",
    "\n",
    "# Physics loss section\n",
    "latex_table += r\"\"\"\\midrule\n",
    "& \\multicolumn{4}{c}{Physics Loss} \\\\\n",
    "\\cmidrule(lr){2-5}\n",
    "Model & Train & Val & Test & Average \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "for i, model_name in enumerate(unique_models):\n",
    "    model_display = model_displays[i]\n",
    "    \n",
    "    phy_train = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'train')]['physics_loss'].values[0]\n",
    "    phy_val = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'val')]['physics_loss'].values[0]\n",
    "    phy_test = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'test')]['physics_loss'].values[0]\n",
    "    phy_avg = (phy_train + phy_val + phy_test) / 3\n",
    "    \n",
    "    is_best_phy_train = abs(phy_train - best_values[('train', 'physics_loss')]) < 1e-10\n",
    "    is_best_phy_val = abs(phy_val - best_values[('val', 'physics_loss')]) < 1e-10\n",
    "    is_best_phy_test = abs(phy_test - best_values[('test', 'physics_loss')]) < 1e-10\n",
    "    \n",
    "    latex_table += f\"{model_display} & {format_value(phy_train, is_best_phy_train)} & {format_value(phy_val, is_best_phy_val)} & {format_value(phy_test, is_best_phy_test)} & {format_value(phy_avg)} \\\\\\\\\\n\"\n",
    "\n",
    "# Total loss section\n",
    "latex_table += r\"\"\"\\midrule\n",
    "& \\multicolumn{4}{c}{Total Loss} \\\\\n",
    "\\cmidrule(lr){2-5}\n",
    "Model & Train & Val & Test & Average \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "for i, model_name in enumerate(unique_models):\n",
    "    model_display = model_displays[i]\n",
    "    \n",
    "    total_train = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'train')]['total_loss'].values[0]\n",
    "    total_val = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'val')]['total_loss'].values[0]\n",
    "    total_test = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'test')]['total_loss'].values[0]\n",
    "    total_avg = (total_train + total_val + total_test) / 3\n",
    "    \n",
    "    is_best_total_train = abs(total_train - best_values[('train', 'total_loss')]) < 1e-10\n",
    "    is_best_total_val = abs(total_val - best_values[('val', 'total_loss')]) < 1e-10\n",
    "    is_best_total_test = abs(total_test - best_values[('test', 'total_loss')]) < 1e-10\n",
    "    \n",
    "    latex_table += f\"{model_display} & {format_value(total_train, is_best_total_train)} & {format_value(total_val, is_best_total_val)} & {format_value(total_test, is_best_total_test)} & {format_value(total_avg)} \\\\\\\\\\n\"\n",
    "\n",
    "# Close the table\n",
    "latex_table += r\"\"\"\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "with open(\"./outputs/results_article_table.txt\", \"w\") as f:\n",
    "    f.write(latex_table)\n",
    "print(\"LaTeX table has been exported to 'results_article_table.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching history for run_1...\n",
      "  Got 10000 data points for run_1\n",
      "Fetching history for run_3...\n",
      "  Got 10000 data points for run_3\n",
      "Fetching history for run_4...\n",
      "  Got 10000 data points for run_4\n",
      "Fetching history for run_8...\n",
      "  Got 10000 data points for run_8\n",
      "Fetching history for run_9...\n",
      "  Got 10000 data points for run_9\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# Set your wandb API key\n",
    "# os.environ[\"WANDB_API_KEY\"] = \"YOUR_API_KEY_HERE\"\n",
    "\n",
    "# Initialize wandb and connect to your project\n",
    "api = wandb.Api()\n",
    "entity = \"enzo-louvard-ensta-paris\"  # Your wandb username or organization\n",
    "project = \"climate_pinn\"             # Your project name\n",
    "\n",
    "# Get runs data\n",
    "runs = api.runs(f\"{entity}/{project}\")\n",
    "\n",
    "# Maximum number of steps to include (adjust as needed)\n",
    "MAX_STEPS = 25000\n",
    "# Sampling rate (to reduce data points and keep chart performant)\n",
    "SAMPLING_RATE = 1  # Get every Nth step\n",
    "\n",
    "# Extract the metrics you need for visualization\n",
    "data = []\n",
    "model_run = {\"run_1\": \"model_0\",\n",
    "             \"run_3\": \"model_1\",\n",
    "             \"run_4\": \"model_0_Re\",\n",
    "             \"run_8\": \"model_2\",\n",
    "             \"run_9\": \"model_3\"}\n",
    "model_data = {}\n",
    "\n",
    "for run in runs:\n",
    "    run_name = run.name\n",
    "    if run_name in [\"run_1\", \"run_3\", \"run_4\", \"run_8\", \"run_9\"]:\n",
    "        print(f\"Fetching history for {run_name}...\")\n",
    "        \n",
    "        # Get the history metrics for data loss\n",
    "        try:\n",
    "            history = run.history(samples=MAX_STEPS//SAMPLING_RATE, keys=[\"batch/data_loss\", \"_step\"])\n",
    "            \n",
    "            # Convert to list of [step, value] pairs and sample every Nth point\n",
    "            steps = history[\"_step\"].tolist()\n",
    "            data_loss = history[\"batch/data_loss\"].tolist()\n",
    "            \n",
    "            # Create pairs of [step, value]\n",
    "            step_loss_pairs = [[steps[i], data_loss[i]] for i in range(len(steps)) if i % SAMPLING_RATE == 0]\n",
    "            \n",
    "            # Store in model_data dictionary\n",
    "            model_data[model_run[run_name]] = {\n",
    "                \"data_loss\": step_loss_pairs\n",
    "            }\n",
    "            \n",
    "            print(f\"  Got {len(step_loss_pairs)} data points for {run_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching history for {run_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x76b3acca7860>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(np.array(model_data['model_2']['data_loss'])[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
