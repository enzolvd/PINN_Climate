{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **0.Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_dataset\n",
    "# from models.model_2_dropout_imp import ClimatePINN\n",
    "from train import plot_comparison\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import xarray as xr\n",
    "from visualisation import load_checkpoint\n",
    "import json\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1.Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    1, \n",
    "    train_val_split = None, \n",
    "    year0=2000, \n",
    "    root_dir=\"./data/era_5_data\",\n",
    "    normalize=True)\n",
    "\n",
    "idx = [0,1,2]\n",
    "inputs, targets = dataset['train'][:]['input'], dataset['train'][:]['target']\n",
    "geo500 , t850 = inputs[:,0,...], inputs[:,1,...]\n",
    "t2m, u, v = targets[:,0,...], targets[:,1,...], targets[:,2,...]\n",
    "inputs = (geo500 , t850)\n",
    "targets = (t2m, u, v)\n",
    "lon, lat= dataset['train'][0]['coords'][0], dataset['train'][0]['coords'][1]\n",
    "dataloader = DataLoader(dataset['train'], batch_size=1, shuffle=False)\n",
    "batch = next(iter(dataloader))\n",
    "inputs = batch['input']\n",
    "targets = batch['target']\n",
    "masks = batch['masks']\n",
    "coords = [coord for coord in batch['coords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = (geo500 , t850, t2m, u, v)\n",
    "\n",
    "corr_matrix = np.zeros((5,5))\n",
    "vars_name = ['input:geo500', 'input:t850', 'target:t2m', 'target:u', 'target:v']\n",
    "corr_matrix = np.zeros((5, 5, 32, 64))\n",
    "import matplotlib.colors as mcolors\n",
    "norm = mcolors.Normalize(vmin=-1, vmax=1)\n",
    "for x, var_x in tqdm(enumerate(vars)):\n",
    "    for y, var_y in enumerate(vars):\n",
    "        corr = pearsonr(var_x, var_y)[0]\n",
    "        corr_matrix[x,y] = corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the arrays\n",
    "vars = (geo500.flatten(), t850.flatten(), t2m.flatten(), u.flatten(), v.flatten())\n",
    "vars_name = ['geo500', 't850', 't2m', 'u', 'v']\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = np.zeros((5, 5))\n",
    "for x, var_x in tqdm(enumerate(vars)):\n",
    "    for y, var_y in enumerate(vars):\n",
    "        corr = pearsonr(var_x, var_y)[0]\n",
    "        corr_matrix[x, y] = corr\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot the correlation matrix\n",
    "im = ax.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "\n",
    "# Add color bar\n",
    "cbar = fig.colorbar(im, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Correlation Coefficient')\n",
    "\n",
    "# Add labels to the matrix\n",
    "ax.set_xticks(np.arange(len(vars_name)))\n",
    "ax.set_yticks(np.arange(len(vars_name)))\n",
    "ax.set_xticklabels(vars_name)\n",
    "ax.set_yticklabels(vars_name)\n",
    "\n",
    "# Rotate the tick labels for better readability\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Add separators\n",
    "ax.axvline(x=1.5, color='black', linewidth=2)\n",
    "ax.axhline(y=1.5, color='black', linewidth=2)\n",
    "\n",
    "# Annotate the cells with the correlation coefficients\n",
    "for i in range(len(vars_name)):\n",
    "    for j in range(len(vars_name)):\n",
    "        text = ax.text(j, i, f\"{corr_matrix[i, j]:.2f}\",\n",
    "                       ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "# Add title\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\n",
    "    10, \n",
    "    train_val_split = 0.8,\n",
    "    root_dir=\"./data/era_5_data\",\n",
    "    year0=1979,\n",
    "    normalize=True)\n",
    "\n",
    "train_dataset, val_dataset = dataset['train'], dataset['val']\n",
    "test_dataset = load_dataset(\n",
    "    1,\n",
    "    train_val_split = None,\n",
    "    year0=2000,\n",
    "    root_dir=\"./data/era_5_data\",\n",
    "    normalize=True)['train']\n",
    "bs = 16 \n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to collect results\n",
    "results_data = []\n",
    "\n",
    "# Define a dictionary of loaders to loop over\n",
    "loaders = {\"test\": test_loader} #{\"train\": train_loader, \"val\": val_loader, \n",
    "runs = ['run_1', 'run_4', 'run_8', 'run_9']\n",
    "\n",
    "for run in tqdm(runs, leave=False, desc=\"Processing runs\"):\n",
    "    model, epoch, config, device, model_name = load_checkpoint(run, device, checkpoints='./checkpoints', verbose=False)\n",
    "    \n",
    "    for ds_name, loader in tqdm(loaders.items(), leave=False, desc=f\"Datasets for {model_name}\"):\n",
    "        model.eval()\n",
    "        mse_loss = 0.0\n",
    "        phy_loss = 0.0\n",
    "        count = 0\n",
    "        \n",
    "        for batch in tqdm(loader, leave=False, desc=f\"Batches in {ds_name}\"):\n",
    "            inp = batch['input'].to(device)\n",
    "            masks = batch['masks'].to(device)\n",
    "            coords = [coord.to(device) for coord in batch['coords']]\n",
    "            target = batch['target'].to(device)\n",
    "            \n",
    "            pred = model(inp, masks, coords)\n",
    "            loss = model.MSE(pred['output'], target)\n",
    "            mse_loss += loss.item()\n",
    "            phy_loss += sum(list(pred['physics_loss'].values())).item()\n",
    "            count += 1\n",
    "            \n",
    "            del inp, masks, coords, target, pred, loss\n",
    "            torch.cuda.empty_cache()\n",
    "                    \n",
    "        avg_mse_loss = mse_loss / count if count > 0 else float('nan')\n",
    "        avg_phy_loss = phy_loss / count if count > 0 else float('nan')\n",
    "        \n",
    "        # Append results to list\n",
    "        results_data.append({\n",
    "            'model_name': model_name,\n",
    "            'dataset': ds_name,\n",
    "            'mse': avg_mse_loss,\n",
    "            'physics_loss': avg_phy_loss,\n",
    "            'total_loss': avg_mse_loss + avg_phy_loss\n",
    "        })\n",
    "        \n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Create DataFrame from collected results after all processing is done\n",
    "results_df = pd.DataFrame(results_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('./outputs/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the seaborn style \n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Option 1: Specify the number of colors needed\n",
    "palette = sns.color_palette(\"Set1\", n_colors=3)\n",
    "\n",
    "# Option 2: Or use a specific palette that's commonly used in pairplots\n",
    "# palette = sns.color_palette(\"deep\")\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "sns.barplot(x='model_name', y='mse', hue='dataset', data=results_df, ax=ax[0], palette=palette)\n",
    "ax[0].set_title(\"MSE Loss\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].set_yscale(\"log\")\n",
    "\n",
    "sns.barplot(x='model_name', y='physics_loss', hue='dataset', data=results_df, ax=ax[1], palette=palette)\n",
    "ax[1].set_title(\"Physics Loss\")\n",
    "ax[1].set_ylabel(\"Loss\")\n",
    "ax[1].set_yscale(\"log\")\n",
    "\n",
    "sns.barplot(x='model_name', y='total_loss', hue='dataset', data=results_df, ax=ax[2], palette=palette)\n",
    "ax[2].set_title(\"Total Loss\")\n",
    "ax[2].set_ylabel(\"Loss\")\n",
    "ax[2].set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./outputs/barplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming results_df already exists with columns 'model_name', 'dataset', 'mse', 'physics_loss', 'total_loss'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Replace underscores in model names for LaTeX display\n",
    "results_df['model_display'] = results_df['model_name'].apply(lambda x: x.replace('_', r'\\_'))\n",
    "\n",
    "# Find the best (minimum) values for each metric in each dataset\n",
    "best_values = {}\n",
    "for dataset in ['train', 'val', 'test']:\n",
    "    dataset_df = results_df[results_df['dataset'] == dataset]\n",
    "    for metric in ['mse', 'physics_loss', 'total_loss']:\n",
    "        best_values[(dataset, metric)] = dataset_df[metric].min()\n",
    "\n",
    "# Format values with scientific notation where appropriate\n",
    "def format_value(value, is_best=False):\n",
    "    if np.isnan(value):\n",
    "        return \"N/A\"\n",
    "    # Use scientific notation for very small values\n",
    "    elif abs(value) < 0.001 or abs(value) >= 10000:\n",
    "        formatted = f\"{value:.2e}\"\n",
    "    else:\n",
    "        formatted = f\"{value:.4f}\"\n",
    "    \n",
    "    # Add bold formatting for best values\n",
    "    if is_best:\n",
    "        return f\"\\\\textbf{{{formatted}}}\"\n",
    "    return formatted\n",
    "\n",
    "# Get unique model names (preserving order)\n",
    "unique_models = results_df[results_df['dataset'] == 'train']['model_name'].tolist()\n",
    "model_displays = results_df[results_df['dataset'] == 'train']['model_display'].tolist()\n",
    "\n",
    "# Create a reorganized table by metric type\n",
    "latex_table = r\"\"\"\\begin{table}[htbp]\n",
    "\\centering\n",
    "\\caption{Comparison of models across different metrics and datasets. Best values in each category are highlighted in bold.}\n",
    "\\label{tab:results}\n",
    "\\begin{tabular}{lcccc}\n",
    "\\toprule\n",
    "& \\multicolumn{4}{c}{MSE} \\\\\n",
    "\\cmidrule(lr){2-5}\n",
    "Model & Train & Val & Test & Average \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "# MSE section\n",
    "for i, model_name in enumerate(unique_models):\n",
    "    model_display = model_displays[i]\n",
    "    \n",
    "    mse_train = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'train')]['mse'].values[0]\n",
    "    mse_val = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'val')]['mse'].values[0]\n",
    "    mse_test = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'test')]['mse'].values[0]\n",
    "    mse_avg = (mse_train + mse_val + mse_test) / 3\n",
    "    \n",
    "    is_best_mse_train = abs(mse_train - best_values[('train', 'mse')]) < 1e-10\n",
    "    is_best_mse_val = abs(mse_val - best_values[('val', 'mse')]) < 1e-10\n",
    "    is_best_mse_test = abs(mse_test - best_values[('test', 'mse')]) < 1e-10\n",
    "    \n",
    "    latex_table += f\"{model_display} & {format_value(mse_train, is_best_mse_train)} & {format_value(mse_val, is_best_mse_val)} & {format_value(mse_test, is_best_mse_test)} & {format_value(mse_avg)} \\\\\\\\\\n\"\n",
    "\n",
    "# Physics loss section\n",
    "latex_table += r\"\"\"\\midrule\n",
    "& \\multicolumn{4}{c}{Physics Loss} \\\\\n",
    "\\cmidrule(lr){2-5}\n",
    "Model & Train & Val & Test & Average \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "for i, model_name in enumerate(unique_models):\n",
    "    model_display = model_displays[i]\n",
    "    \n",
    "    phy_train = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'train')]['physics_loss'].values[0]\n",
    "    phy_val = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'val')]['physics_loss'].values[0]\n",
    "    phy_test = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'test')]['physics_loss'].values[0]\n",
    "    phy_avg = (phy_train + phy_val + phy_test) / 3\n",
    "    \n",
    "    is_best_phy_train = abs(phy_train - best_values[('train', 'physics_loss')]) < 1e-10\n",
    "    is_best_phy_val = abs(phy_val - best_values[('val', 'physics_loss')]) < 1e-10\n",
    "    is_best_phy_test = abs(phy_test - best_values[('test', 'physics_loss')]) < 1e-10\n",
    "    \n",
    "    latex_table += f\"{model_display} & {format_value(phy_train, is_best_phy_train)} & {format_value(phy_val, is_best_phy_val)} & {format_value(phy_test, is_best_phy_test)} & {format_value(phy_avg)} \\\\\\\\\\n\"\n",
    "\n",
    "# Total loss section\n",
    "latex_table += r\"\"\"\\midrule\n",
    "& \\multicolumn{4}{c}{Total Loss} \\\\\n",
    "\\cmidrule(lr){2-5}\n",
    "Model & Train & Val & Test & Average \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "for i, model_name in enumerate(unique_models):\n",
    "    model_display = model_displays[i]\n",
    "    \n",
    "    total_train = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'train')]['total_loss'].values[0]\n",
    "    total_val = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'val')]['total_loss'].values[0]\n",
    "    total_test = results_df[(results_df['model_name'] == model_name) & (results_df['dataset'] == 'test')]['total_loss'].values[0]\n",
    "    total_avg = (total_train + total_val + total_test) / 3\n",
    "    \n",
    "    is_best_total_train = abs(total_train - best_values[('train', 'total_loss')]) < 1e-10\n",
    "    is_best_total_val = abs(total_val - best_values[('val', 'total_loss')]) < 1e-10\n",
    "    is_best_total_test = abs(total_test - best_values[('test', 'total_loss')]) < 1e-10\n",
    "    \n",
    "    latex_table += f\"{model_display} & {format_value(total_train, is_best_total_train)} & {format_value(total_val, is_best_total_val)} & {format_value(total_test, is_best_total_test)} & {format_value(total_avg)} \\\\\\\\\\n\"\n",
    "\n",
    "# Close the table\n",
    "latex_table += r\"\"\"\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "with open(\"./outputs/results_article_table.txt\", \"w\") as f:\n",
    "    f.write(latex_table)\n",
    "print(\"LaTeX table has been exported to 'results_article_table.txt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
